
[2024-10-01 20:58:25,899] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[93m [WARNING] [39m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [39m async_io: please install the libaio-dev package with apt
[93m [WARNING] [39m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [39m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [39m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [39m using untested triton version (2.3.1), only 1.0.0 is known to be compatible
[2024-10-01 20:58:31,852] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-10-01 20:58:31,852] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
max_steps is given, it will override any value given in num_train_epochs
[34m[1mwandb[39m[22m: [33mWARNING[39m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.
  0%|                                                                                                                                                                                | 0/30000 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)


 33%|██████████████████████████████████████████████████████▎                                                                                                            | 10004/30000 [00:22<01:00, 330.13it/s]




 33%|██████████████████████████████████████████████████████▋                                                                                                             | 10009/30000 [00:51<03:53, 85.67it/s]





 33%|██████████████████████████████████████████████████████▋                                                                                                             | 10015/30000 [01:27<10:07, 32.88it/s]





 33%|██████████████████████████████████████████████████████▊                                                                                                             | 10020/30000 [01:57<32:50, 10.14it/s]



 33%|██████████████████████████████████████████████████████▏                                                                                                           | 10025/30000 [02:25<1:15:31,  4.41it/s]


 33%|██████████████████████████████████████████████████████▏                                                                                                           | 10029/30000 [02:51<1:29:01,  3.74it/s]





 33%|██████████████████████████████████████████████████████▏                                                                                                           | 10035/30000 [03:23<4:49:35,  1.15it/s]




 33%|██████████████████████████████████████████████████████▏                                                                                                           | 10039/30000 [03:51<8:30:51,  1.54s/it]




 33%|█████████████████████████████████████████████████████▉                                                                                                           | 10044/30000 [04:14<17:25:20,  3.14s/it]






 34%|█████████████████████████████████████████████████████▉                                                                                                           | 10050/30000 [04:50<28:11:16,  5.09s/it]




 34%|█████████████████████████████████████████████████████▉                                                                                                           | 10054/30000 [05:14<31:20:58,  5.66s/it]






 34%|█████████████████████████████████████████████████████▉                                                                                                           | 10060/30000 [05:49<32:11:10,  5.81s/it]




 34%|██████████████████████████████████████████████████████                                                                                                           | 10064/30000 [06:13<32:20:38,  5.84s/it]





 34%|██████████████████████████████████████████████████████                                                                                                           | 10069/30000 [06:43<33:17:28,  6.01s/it]





 34%|██████████████████████████████████████████████████████                                                                                                           | 10074/30000 [07:12<33:10:36,  5.99s/it]





 34%|██████████████████████████████████████████████████████                                                                                                           | 10079/30000 [07:41<32:23:18,  5.85s/it]






 34%|██████████████████████████████████████████████████████                                                                                                           | 10085/30000 [08:17<34:28:40,  6.23s/it]





 34%|██████████████████████████████████████████████████████▏                                                                                                          | 10090/30000 [08:47<32:52:24,  5.94s/it]





 34%|██████████████████████████████████████████████████████▏                                                                                                          | 10095/30000 [09:15<31:38:00,  5.72s/it]





 34%|██████████████████████████████████████████████████████▏                                                                                                          | 10100/30000 [09:44<31:22:49,  5.68s/it]




 34%|██████████████████████████████████████████████████████▏                                                                                                          | 10104/30000 [10:07<32:20:16,  5.85s/it]




 34%|██████████████████████████████████████████████████████▎                                                                                                          | 10109/30000 [10:38<33:48:11,  6.12s/it]





 34%|██████████████████████████████████████████████████████▎                                                                                                          | 10114/30000 [11:09<34:16:42,  6.21s/it]






 34%|██████████████████████████████████████████████████████▎                                                                                                          | 10120/30000 [11:44<32:44:51,  5.93s/it]




 34%|██████████████████████████████████████████████████████▎                                                                                                          | 10124/30000 [12:07<32:39:00,  5.91s/it]





 34%|██████████████████████████████████████████████████████▎                                                                                                          | 10129/30000 [12:36<32:31:44,  5.89s/it]





 34%|██████████████████████████████████████████████████████▍                                                                                                          | 10134/30000 [13:04<31:43:14,  5.75s/it]






 34%|██████████████████████████████████████████████████████▍                                                                                                          | 10140/30000 [13:40<31:54:22,  5.78s/it]





 34%|██████████████████████████████████████████████████████▍                                                                                                          | 10145/30000 [14:10<32:23:01,  5.87s/it]





 34%|██████████████████████████████████████████████████████▍                                                                                                          | 10150/30000 [14:39<31:38:55,  5.74s/it]





 34%|██████████████████████████████████████████████████████▍                                                                                                          | 10155/30000 [15:08<32:11:43,  5.84s/it]





 34%|██████████████████████████████████████████████████████▌                                                                                                          | 10160/30000 [15:36<30:48:57,  5.59s/it]




 34%|██████████████████████████████████████████████████████▌                                                                                                          | 10164/30000 [15:59<31:43:15,  5.76s/it]






 34%|██████████████████████████████████████████████████████▌                                                                                                          | 10170/30000 [16:36<32:52:07,  5.97s/it]





 34%|██████████████████████████████████████████████████████▌                                                                                                          | 10175/30000 [17:06<32:48:08,  5.96s/it]




 34%|██████████████████████████████████████████████████████▋                                                                                                          | 10179/30000 [17:29<32:25:49,  5.89s/it]





 34%|██████████████████████████████████████████████████████▋                                                                                                          | 10184/30000 [17:59<33:07:02,  6.02s/it]






 34%|██████████████████████████████████████████████████████▋                                                                                                          | 10190/30000 [18:34<32:04:42,  5.83s/it]





 34%|██████████████████████████████████████████████████████▋                                                                                                          | 10195/30000 [19:04<32:42:39,  5.95s/it]





 34%|██████████████████████████████████████████████████████▋                                                                                                          | 10200/30000 [19:33<31:36:53,  5.75s/it]




 34%|██████████████████████████████████████████████████████▊                                                                                                          | 10204/30000 [19:55<31:37:00,  5.75s/it]






 34%|██████████████████████████████████████████████████████▊                                                                                                          | 10210/30000 [20:30<32:30:01,  5.91s/it]




 34%|██████████████████████████████████████████████████████▊                                                                                                          | 10214/30000 [20:53<31:55:16,  5.81s/it]






 34%|██████████████████████████████████████████████████████▊                                                                                                          | 10220/30000 [21:30<33:22:09,  6.07s/it]





 34%|██████████████████████████████████████████████████████▊                                                                                                          | 10225/30000 [22:00<33:24:05,  6.08s/it]





 34%|██████████████████████████████████████████████████████▉                                                                                                          | 10230/30000 [22:30<32:30:15,  5.92s/it]





 34%|██████████████████████████████████████████████████████▉                                                                                                          | 10235/30000 [22:58<31:04:37,  5.66s/it]





 34%|██████████████████████████████████████████████████████▉                                                                                                          | 10240/30000 [23:27<32:01:45,  5.84s/it]




 34%|██████████████████████████████████████████████████████▉                                                                                                          | 10244/30000 [23:50<32:30:12,  5.92s/it][rank0]: Traceback (most recent call last):
[rank0]:   File "/home/jingbo/KVMemory/finetune_combine.py", line 91, in <module>
[rank0]:     main()
[rank0]:   File "/home/jingbo/KVMemory/finetune_combine.py", line 85, in main
[rank0]:     trainer.train(resume_from_checkpoint = True)
[rank0]:   File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/transformers/trainer.py", line 1938, in train
[rank0]:     return inner_training_loop(
[rank0]:   File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/transformers/trainer.py", line 2279, in _inner_training_loop
[rank0]:     tr_loss_step = self.training_step(model, inputs)
[rank0]:   File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/transformers/trainer.py", line 3318, in training_step
[rank0]:     loss = self.compute_loss(model, inputs)
[rank0]:   File "/home/jingbo/KVMemory/src/training/trainer.py", line 332, in compute_loss
[rank0]:     outputs = self.model(input_ids=input_ids, attention_mask=attention_mask, labels = input_ids)
[rank0]:   File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/peft/peft_model.py", line 1430, in forward
[rank0]:     return self.base_model(
[rank0]:   File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/peft/tuners/tuners_utils.py", line 179, in forward
[rank0]:     return self.model.forward(*args, **kwargs)
[rank0]:   File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py", line 1159, in forward
[rank0]:     logits = logits.float()
[rank0]: torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 384.00 MiB. GPU