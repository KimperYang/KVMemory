
  0%|                                                                            | 0/10000 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)
torch.Size([2, 1076]) torch.Size([2, 1577]) 32 torch.Size([2, 32, 501, 128])
tensor(2.0542, device='cuda:0', grad_fn=<DivBackward0>)
torch.Size([2, 1547]) torch.Size([2, 2048]) 32 torch.Size([2, 32, 501, 128])
tensor(1.4660, device='cuda:0', grad_fn=<DivBackward0>)
torch.Size([2, 1547]) torch.Size([2, 2048]) 32 torch.Size([2, 32, 501, 128])
tensor(2.0132, device='cuda:0', grad_fn=<DivBackward0>)
torch.Size([2, 1033]) torch.Size([2, 1534]) 32 torch.Size([2, 32, 501, 128])
  0%|                                                                 | 1/10000 [00:05<14:12:31,  5.12s/it]
tensor(2.0925, device='cuda:0', grad_fn=<DivBackward0>)
torch.Size([2, 1482]) torch.Size([2, 1983]) 32 torch.Size([2, 32, 501, 128])
tensor(2.1172, device='cuda:0', grad_fn=<DivBackward0>)
torch.Size([2, 761]) torch.Size([2, 1262]) 32 torch.Size([2, 32, 501, 128])
tensor(1.8649, device='cuda:0', grad_fn=<DivBackward0>)
torch.Size([2, 1547]) torch.Size([2, 2048]) 32 torch.Size([2, 32, 501, 128])

  0%|                                                                 | 2/10000 [00:09<13:49:00,  4.98s/it]
torch.Size([2, 1547]) torch.Size([2, 2048]) 32 torch.Size([2, 32, 501, 128])
tensor(1.5606, device='cuda:0', grad_fn=<DivBackward0>)
torch.Size([2, 830]) torch.Size([2, 1331]) 32 torch.Size([2, 32, 501, 128])
tensor(1.9434, device='cuda:0', grad_fn=<DivBackward0>)
torch.Size([2, 1547]) torch.Size([2, 2048]) 32 torch.Size([2, 32, 501, 128])
tensor(2.2499, device='cuda:0', grad_fn=<DivBackward0>)

  0%|                                                                 | 3/10000 [00:14<12:55:55,  4.66s/it]
tensor(1.9986, device='cuda:0', grad_fn=<DivBackward0>)
torch.Size([2, 1343]) torch.Size([2, 1844]) 32 torch.Size([2, 32, 501, 128])
tensor(2.1861, device='cuda:0', grad_fn=<DivBackward0>)
torch.Size([2, 1547]) torch.Size([2, 2048]) 32 torch.Size([2, 32, 501, 128])
tensor(1.9618, device='cuda:0', grad_fn=<DivBackward0>)
torch.Size([2, 1547]) torch.Size([2, 2048]) 32 torch.Size([2, 32, 501, 128])
tensor(1.6660, device='cuda:0', grad_fn=<DivBackward0>)
torch.Size([2, 1547]) torch.Size([2, 2048]) 32 torch.Size([2, 32, 501, 128])

  0%|                                                                 | 4/10000 [00:19<13:54:30,  5.01s/it]
torch.Size([2, 1547]) torch.Size([2, 2048]) 32 torch.Size([2, 32, 501, 128])
tensor(2.3733, device='cuda:0', grad_fn=<DivBackward0>)
torch.Size([2, 1547]) torch.Size([2, 2048]) 32 torch.Size([2, 32, 501, 128])
tensor(2.1162, device='cuda:0', grad_fn=<DivBackward0>)
torch.Size([2, 804]) torch.Size([2, 1305]) 32 torch.Size([2, 32, 501, 128])
tensor(2.0694, device='cuda:0', grad_fn=<DivBackward0>)

  0%|                                                                 | 5/10000 [00:24<13:47:57,  4.97s/it]
tensor(2.0948, device='cuda:0', grad_fn=<DivBackward0>)
torch.Size([2, 1547]) torch.Size([2, 2048]) 32 torch.Size([2, 32, 501, 128])
tensor(2.0862, device='cuda:0', grad_fn=<DivBackward0>)
{'loss': 1.9834, 'grad_norm': 0.1801772117614746, 'learning_rate': 1.9990000000000003e-05, 'epoch': 0.0}
torch.Size([2, 1024]) torch.Size([2, 1525]) 32 torch.Size([2, 32, 501, 128])
tensor(2.2058, device='cuda:0', grad_fn=<DivBackward0>)
torch.Size([2, 1547]) torch.Size([2, 2048]) 32 torch.Size([2, 32, 501, 128])
tensor(1.7315, device='cuda:0', grad_fn=<DivBackward0>)
torch.Size([2, 710]) torch.Size([2, 1211]) 32 torch.Size([2, 32, 501, 128])
tensor(2.0568, device='cuda:0', grad_fn=<DivBackward0>)

  0%|                                                                 | 6/10000 [00:29<13:25:08,  4.83s/it]
tensor(2.1046, device='cuda:0', grad_fn=<DivBackward0>)
torch.Size([2, 1547]) torch.Size([2, 2048]) 32 torch.Size([2, 32, 501, 128])
tensor(1.9446, device='cuda:0', grad_fn=<DivBackward0>)
torch.Size([2, 1547]) torch.Size([2, 2048]) 32 torch.Size([2, 32, 501, 128])
tensor(1.7674, device='cuda:0', grad_fn=<DivBackward0>)
torch.Size([2, 690]) torch.Size([2, 1191]) 32 torch.Size([2, 32, 501, 128])

  0%|                                                                 | 7/10000 [00:34<13:18:38,  4.80s/it]
torch.Size([2, 1239]) torch.Size([2, 1740]) 32 torch.Size([2, 32, 501, 128])
tensor(1.7611, device='cuda:0', grad_fn=<DivBackward0>)
torch.Size([2, 991]) torch.Size([2, 1492]) 32 torch.Size([2, 32, 501, 128])
tensor(2.3097, device='cuda:0', grad_fn=<DivBackward0>)
torch.Size([2, 1151]) torch.Size([2, 1652]) 32 torch.Size([2, 32, 501, 128])
tensor(2.1618, device='cuda:0', grad_fn=<DivBackward0>)
torch.Size([2, 984]) torch.Size([2, 1485]) 32 torch.Size([2, 32, 501, 128])

  0%|                                                                 | 8/10000 [00:38<13:00:17,  4.69s/it]
torch.Size([2, 1547]) torch.Size([2, 2048]) 32 torch.Size([2, 32, 501, 128])
tensor(1.8778, device='cuda:0', grad_fn=<DivBackward0>)
torch.Size([2, 1547]) torch.Size([2, 2048]) 32 torch.Size([2, 32, 501, 128])
tensor(2.1789, device='cuda:0', grad_fn=<DivBackward0>)
torch.Size([2, 1547]) torch.Size([2, 2048]) 32 torch.Size([2, 32, 501, 128])
tensor(1.8188, device='cuda:0', grad_fn=<DivBackward0>)
torch.Size([2, 1547]) torch.Size([2, 2048]) 32 torch.Size([2, 32, 501, 128])

  0%|                                                                 | 9/10000 [00:43<13:12:10,  4.76s/it]
torch.Size([2, 664]) torch.Size([2, 1165]) 32 torch.Size([2, 32, 501, 128])
tensor(2.0598, device='cuda:0', grad_fn=<DivBackward0>)
torch.Size([2, 1547]) torch.Size([2, 2048]) 32 torch.Size([2, 32, 501, 128])
tensor(1.7008, device='cuda:0', grad_fn=<DivBackward0>)
torch.Size([2, 1547]) torch.Size([2, 2048]) 32 torch.Size([2, 32, 501, 128])
tensor(2.0589, device='cuda:0', grad_fn=<DivBackward0>)
torch.Size([2, 704]) torch.Size([2, 1205]) 32 torch.Size([2, 32, 501, 128])

  0%|                                                                | 10/10000 [00:48<13:21:37,  4.81s/it]
torch.Size([2, 1547]) torch.Size([2, 2048]) 32 torch.Size([2, 32, 501, 128])
tensor(2.1751, device='cuda:0', grad_fn=<DivBackward0>)
{'loss': 1.9773, 'grad_norm': 0.4409180283546448, 'learning_rate': 1.9980000000000002e-05, 'epoch': 0.0}
torch.Size([2, 1140]) torch.Size([2, 1641]) 32 torch.Size([2, 32, 501, 128])
tensor(2.0267, device='cuda:0', grad_fn=<DivBackward0>)
torch.Size([2, 1547]) torch.Size([2, 2048]) 32 torch.Size([2, 32, 501, 128])

  0%|                                                                | 11/10000 [00:53<13:15:43,  4.78s/it]
torch.Size([2, 1547]) torch.Size([2, 2048]) 32 torch.Size([2, 32, 501, 128])
tensor(2.3593, device='cuda:0', grad_fn=<DivBackward0>)
torch.Size([2, 747]) torch.Size([2, 1248]) 32 torch.Size([2, 32, 501, 128])
tensor(1.9964, device='cuda:0', grad_fn=<DivBackward0>)
torch.Size([2, 1547]) torch.Size([2, 2048]) 32 torch.Size([2, 32, 501, 128])
tensor(2.0828, device='cuda:0', grad_fn=<DivBackward0>)
torch.Size([2, 1015]) torch.Size([2, 1516]) 32 torch.Size([2, 32, 501, 128])
tensor(2.0106, device='cuda:0', grad_fn=<DivBackward0>)
torch.Size([2, 1547]) torch.Size([2, 2048]) 32 torch.Size([2, 32, 501, 128])
  0%|                                                                | 11/10000 [00:53<13:15:43,  4.78s/it]Traceback (most recent call last):
  File "/home/jingbo/KVMemory/finetune.py", line 83, in <module>
    main()
  File "/home/jingbo/KVMemory/finetune.py", line 75, in main
    trainer.train()
  File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/transformers/trainer.py", line 1938, in train
    return inner_training_loop(
  File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/transformers/trainer.py", line 2274, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
  File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/transformers/trainer.py", line 3313, in training_step
    loss = self.compute_loss(model, inputs)
  File "/home/jingbo/KVMemory/src/training/trainer.py", line 35, in compute_loss
    outputs = self.model(input_ids=remaining_ids_batch, attention_mask=attention_mask, labels = remaining_ids_batch, past_key_values=past_key_values_batch, use_cache=True)
  File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/peft/peft_model.py", line 1430, in forward
    return self.base_model(
  File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/peft/tuners/tuners_utils.py", line 179, in forward
    return self.model.forward(*args, **kwargs)
  File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py", line 1069, in forward
    outputs = self.model(
  File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py", line 873, in forward
    layer_outputs = decoder_layer(
  File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py", line 612, in forward
    hidden_states, self_attn_weights, present_key_value = self.self_attn(
  File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py", line 450, in forward
    attn_output = _flash_attention_forward(
  File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/transformers/modeling_flash_attention_utils.py", line 186, in _flash_attention_forward
    query_states, key_states, value_states, indices_q, cu_seq_lens, max_seq_lens = _upad_input(
  File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/transformers/modeling_flash_attention_utils.py", line 98, in _upad_input
    indices_k, cu_seqlens_k, max_seqlen_in_batch_k = _get_unpad_data(attention_mask)
  File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/transformers/modeling_flash_attention_utils.py", line 49, in _get_unpad_data
    indices = torch.nonzero(attention_mask.flatten(), as_tuple=False).flatten()
KeyboardInterrupt
[rank0]: Traceback (most recent call last):
[rank0]:   File "/home/jingbo/KVMemory/finetune.py", line 83, in <module>
[rank0]:     main()
[rank0]:   File "/home/jingbo/KVMemory/finetune.py", line 75, in main
[rank0]:     trainer.train()
[rank0]:   File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/transformers/trainer.py", line 1938, in train
[rank0]:     return inner_training_loop(
[rank0]:   File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/transformers/trainer.py", line 2274, in _inner_training_loop
[rank0]:     tr_loss_step = self.training_step(model, inputs)
[rank0]:   File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/transformers/trainer.py", line 3313, in training_step
[rank0]:     loss = self.compute_loss(model, inputs)
[rank0]:   File "/home/jingbo/KVMemory/src/training/trainer.py", line 35, in compute_loss
[rank0]:     outputs = self.model(input_ids=remaining_ids_batch, attention_mask=attention_mask, labels = remaining_ids_batch, past_key_values=past_key_values_batch, use_cache=True)
[rank0]:   File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/peft/peft_model.py", line 1430, in forward
[rank0]:     return self.base_model(
[rank0]:   File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/peft/tuners/tuners_utils.py", line 179, in forward
[rank0]:     return self.model.forward(*args, **kwargs)
[rank0]:   File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py", line 1069, in forward
[rank0]:     outputs = self.model(
[rank0]:   File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py", line 873, in forward
[rank0]:     layer_outputs = decoder_layer(
[rank0]:   File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py", line 612, in forward
[rank0]:     hidden_states, self_attn_weights, present_key_value = self.self_attn(
[rank0]:   File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py", line 450, in forward
[rank0]:     attn_output = _flash_attention_forward(
[rank0]:   File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/transformers/modeling_flash_attention_utils.py", line 186, in _flash_attention_forward
[rank0]:     query_states, key_states, value_states, indices_q, cu_seq_lens, max_seq_lens = _upad_input(
[rank0]:   File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/transformers/modeling_flash_attention_utils.py", line 98, in _upad_input
[rank0]:     indices_k, cu_seqlens_k, max_seqlen_in_batch_k = _get_unpad_data(attention_mask)
[rank0]:   File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/transformers/modeling_flash_attention_utils.py", line 49, in _get_unpad_data
[rank0]:     indices = torch.nonzero(attention_mask.flatten(), as_tuple=False).flatten()
[rank0]: KeyboardInterrupt
torch.Size([2, 1224]) torch.Size([2, 1725]) 32 torch.Size([2, 32, 501, 128])