
  0%|                                                                                                                                                                                                                                                                                                | 0/30000 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)



 33%|███████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                                                                       | 10005/30000 [00:31<01:31, 217.78it/s]



 33%|████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                                                                                        | 10010/30000 [01:01<04:42, 70.70it/s]



 33%|████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                                                                       | 10015/30000 [01:31<11:00, 30.28it/s]



 33%|████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                                                                       | 10020/30000 [02:01<24:07, 13.81it/s]


 33%|████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                                                                       | 10024/30000 [02:24<42:40,  7.80it/s]




 33%|███████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                                                                      | 10030/30000 [03:00<1:20:34,  4.13it/s]



 33%|███████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                                                                      | 10032/30000 [03:12<2:43:05,  2.04it/s]




 33%|███████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                                                                      | 10040/30000 [04:01<8:21:22,  1.51s/it]




 33%|███████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                                                                                     | 10045/30000 [04:31<13:37:33,  2.46s/it]





 34%|███████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                                                                                     | 10050/30000 [05:01<24:39:39,  4.45s/it]




 34%|███████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                                                                                     | 10054/30000 [05:25<30:45:16,  5.55s/it]





 34%|███████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                                                                     | 10059/30000 [05:54<32:30:35,  5.87s/it]






 34%|███████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                                                                     | 10065/30000 [06:30<32:35:12,  5.88s/it]





 34%|███████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                                                                     | 10070/30000 [06:59<32:51:38,  5.94s/it]





 34%|███████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                                                                     | 10075/30000 [07:29<33:09:55,  5.99s/it]




 34%|███████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                                                                     | 10079/30000 [07:52<32:52:03,  5.94s/it]





 34%|███████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                                                                     | 10084/30000 [08:23<33:34:22,  6.07s/it]






 34%|███████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                                                                     | 10090/30000 [08:59<33:54:07,  6.13s/it]





 34%|███████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                                                                     | 10095/30000 [09:29<33:20:03,  6.03s/it]





 34%|███████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                                                                     | 10100/30000 [09:58<32:14:43,  5.83s/it]





 34%|███████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                                                                     | 10105/30000 [10:27<32:50:55,  5.94s/it]




 34%|███████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                                                                     | 10109/30000 [10:51<32:50:28,  5.94s/it]Traceback (most recent call last):
  File "/home/jingbo/KVMemory/finetune_combine.py", line 91, in <module>
    main()
  File "/home/jingbo/KVMemory/finetune_combine.py", line 85, in main
    trainer.train(resume_from_checkpoint = True)
  File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/transformers/trainer.py", line 1938, in train
    return inner_training_loop(
  File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/transformers/trainer.py", line 2279, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
  File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/transformers/trainer.py", line 3318, in training_step
    loss = self.compute_loss(model, inputs)
  File "/home/jingbo/KVMemory/src/training/trainer.py", line 331, in compute_loss
    outputs = self.model(input_ids=input_ids, attention_mask=attention_mask, labels = input_ids)
  File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/peft/peft_model.py", line 1430, in forward
    return self.base_model(
  File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/peft/tuners/tuners_utils.py", line 179, in forward
    return self.model.forward(*args, **kwargs)
  File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py", line 1139, in forward
    outputs = self.model(
  File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py", line 942, in forward
    layer_outputs = decoder_layer(
  File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py", line 693, in forward
    hidden_states = self.mlp(hidden_states)
  File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py", line 253, in forward
    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))
  File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 116, in forward
    return F.linear(input, self.weight, self.bias)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 26.00 MiB. GPU
[rank0]: Traceback (most recent call last):
[rank0]:   File "/home/jingbo/KVMemory/finetune_combine.py", line 91, in <module>
[rank0]:     main()
[rank0]:   File "/home/jingbo/KVMemory/finetune_combine.py", line 85, in main
[rank0]:     trainer.train(resume_from_checkpoint = True)
[rank0]:   File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/transformers/trainer.py", line 1938, in train
[rank0]:     return inner_training_loop(
[rank0]:   File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/transformers/trainer.py", line 2279, in _inner_training_loop
[rank0]:     tr_loss_step = self.training_step(model, inputs)
[rank0]:   File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/transformers/trainer.py", line 3318, in training_step
[rank0]:     loss = self.compute_loss(model, inputs)
[rank0]:   File "/home/jingbo/KVMemory/src/training/trainer.py", line 331, in compute_loss
[rank0]:     outputs = self.model(input_ids=input_ids, attention_mask=attention_mask, labels = input_ids)
[rank0]:   File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/peft/peft_model.py", line 1430, in forward
[rank0]:     return self.base_model(
[rank0]:   File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/peft/tuners/tuners_utils.py", line 179, in forward
[rank0]:     return self.model.forward(*args, **kwargs)
[rank0]:   File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py", line 1139, in forward
[rank0]:     outputs = self.model(
[rank0]:   File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py", line 942, in forward
[rank0]:     layer_outputs = decoder_layer(
[rank0]:   File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py", line 693, in forward
[rank0]:     hidden_states = self.mlp(hidden_states)
[rank0]:   File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py", line 253, in forward
[rank0]:     down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))
[rank0]:   File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/jingbo/anaconda3/envs/unlearning/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 116, in forward
[rank0]:     return F.linear(input, self.weight, self.bias)
[rank0]: torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 26.00 MiB. GPU